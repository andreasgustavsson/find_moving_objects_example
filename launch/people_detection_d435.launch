<?xml version="1.0" encoding="utf-8"?>
<launch>

<!--  Rviz coordinate system: x=red, y=green, z=blue  -->
<!--  roscore is automatically started if roslaunch detects that it is not already running  -->
  
<!--   <param name="use_sim_time" value="true"/>  -->

  <env name="ROSCONSOLE_CONFIG_FILE"
       value="$(find find_moving_objects)/logger_config/logger_config_debug.config"/>
 
  <arg name="interpreter_extra_args"
       default=""
       doc="Additional args for the pointcloud2 interpreter"
       />
  
  <arg name="frame_broadcaster_extra_args"
       default=""
       doc="Additional args for the frame broadcaster"
       />

  <node pkg="rviz" 
        type="rviz" 
        name="rviz" 
        args="--display-config /home/andreas/.rviz/all_d435_topics.rviz"
        required="true"
        />

  <include file="$(find realsense2_camera)/launch/rs_camera.launch">
           <arg name="enable_pointcloud" value="true"/>
           <arg name="align_depth" value="true"/>
           <arg name="enable_sync" value="true"/>
  </include>
  
  <node pkg="unicorn_sensor_interpreter"
        type="unicorn_pointcloud2_interpreter_node"
        name="pointcloud2_interpreter"
        args="--print_all_options
              --subscribe_topic /camera/depth/color/points
              --sensor_frame_has_z_axis_forward
              --fixed_frame camera_depth_optical_frame
              --subscribe_buffer_size 1
              --publish_ema
              --ema_alpha 1.0
              --publish_objects_closest_point_markers
              --publish_objects_velocity_arrows
              --publish_objects_delta_position_lines
              --velocity_arrows_use_sensor_frame
              --delta_position_lines_use_sensor_frame
              --nr_scans_in_bank 11
              --nr_points_per_scan_in_bank 360
              --voxel_leaf_size 0.01
              --threshold_z_min 0
              --threshold_z_max 1
              --object_threshold_min_speed 0.03
              --object_threshold_max_distance 6.5
              --object_threshold_min_nr_points 4
              --object_threshold_min_confidence 0
              --object_threshold_edge_max_delta_range 0.15
              --object_threshold_max_delta_width_in_points 1000
              $(arg interpreter_extra_args)"
        output="screen"
        />
<!--   launch-prefix="valgrind - -tool=massif " -->
  

  <node pkg="unicorn_sensor_interpreter"
        type="moa_receiver_node"
        name="moa_receiver"
        />
  
  <node pkg="unicorn_sensor_interpreter"
        type="d435_frame_broadcaster_node"
        name="frame_broadcaster" 
        args="$(arg frame_broadcaster_extra_args)"
        />
  
<!--  <node pkg="unicorn_sensor_interpreter"
        type="unicorn_frame_broadcaster_node"
        name="frame_broadcaster" 
        args="$(arg frame_broadcaster_extra_args)"
        />-->

<!--   <node pkg="unicorn_sensor_interpreter" type="face_detector_markerarray_node" name="face_detector_drawer"/> -->
  
  <node pkg="face_detector" type="face_detector" name="face_detector">
    <remap from="camera" to="camera" />
    <remap from="rgb_ns" to="color" />
    <remap from="depth_ns" to="depth" />
    <remap from="image_topic" to="image_raw" />
    <remap from="depth_topic" to="image_rect_raw" />
    <param name="fixed_frame" type="string" value="camera_link" />
    
    <param name="classifier_name" type="string" value="frontalface" />
    <rosparam command="load" file="$(find face_detector)/param/classifier.yaml" />
    <param name="classifier_reliability" type="double" value="0.9" />
    <param name="do_continuous" type="bool" value="true" />
    <param name="do_publish_faces_of_unknown_size" type="bool" value="false" />
    <param name="do_display" type="bool" value="false" />
    <param name="use_rgbd" type="bool" value="true" />
    <param name="approximate_sync" type="bool" value="true" />
  </node>
  
  
  
</launch>
